{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lwGwzSF13IC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries"
      ],
      "metadata": {
        "id": "CM1jdWIsh209"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SESqGIIxh46g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Models"
      ],
      "metadata": {
        "id": "foWKXkN6ie6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n"
      ],
      "metadata": {
        "id": "8Pz1qon5igE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Data"
      ],
      "metadata": {
        "id": "BcBebT0RinR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "VsK_3vhAiqVN",
        "outputId": "227ba6e3-bae4-4396-ae7c-068d9309d267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7866308c-76f7-4f9b-87bf-626bce24376f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7866308c-76f7-4f9b-87bf-626bce24376f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart_disease_uci.csv to heart_disease_uci (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('heart_disease_uci.csv')  # Use exact file name\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Rdk_iN4jkNyY",
        "outputId": "c012a981-d959-448b-88d8-e879b6ea53aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
              "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
              "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
              "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
              "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
              "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
              "\n",
              "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
              "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
              "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
              "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
              "3          normal   187.0  False      3.5  downsloping  0.0   \n",
              "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
              "\n",
              "                thal  num  \n",
              "0       fixed defect    0  \n",
              "1             normal    2  \n",
              "2  reversable defect    1  \n",
              "3             normal    0  \n",
              "4             normal    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c20469ce-b32e-4dae-b347-fce1f92918cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>dataset</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalch</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>typical angina</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>True</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>150.0</td>\n",
              "      <td>False</td>\n",
              "      <td>2.3</td>\n",
              "      <td>downsloping</td>\n",
              "      <td>0.0</td>\n",
              "      <td>fixed defect</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>67</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>asymptomatic</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>False</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>108.0</td>\n",
              "      <td>True</td>\n",
              "      <td>1.5</td>\n",
              "      <td>flat</td>\n",
              "      <td>3.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>67</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>asymptomatic</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>False</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>129.0</td>\n",
              "      <td>True</td>\n",
              "      <td>2.6</td>\n",
              "      <td>flat</td>\n",
              "      <td>2.0</td>\n",
              "      <td>reversable defect</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>Male</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>non-anginal</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>False</td>\n",
              "      <td>normal</td>\n",
              "      <td>187.0</td>\n",
              "      <td>False</td>\n",
              "      <td>3.5</td>\n",
              "      <td>downsloping</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>41</td>\n",
              "      <td>Female</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>atypical angina</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>False</td>\n",
              "      <td>lv hypertrophy</td>\n",
              "      <td>172.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.4</td>\n",
              "      <td>upsloping</td>\n",
              "      <td>0.0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c20469ce-b32e-4dae-b347-fce1f92918cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c20469ce-b32e-4dae-b347-fce1f92918cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c20469ce-b32e-4dae-b347-fce1f92918cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cea3d8dc-23db-4db3-b825-31352348c9fc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cea3d8dc-23db-4db3-b825-31352348c9fc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cea3d8dc-23db-4db3-b825-31352348c9fc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 920,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 265,\n        \"min\": 1,\n        \"max\": 920,\n        \"num_unique_values\": 920,\n        \"samples\": [\n          320,\n          378,\n          539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 28,\n        \"max\": 77,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          64,\n          74,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hungary\",\n          \"VA Long Beach\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"asymptomatic\",\n          \"atypical angina\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.066069518587458,\n        \"min\": 0.0,\n        \"max\": 200.0,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          145.0,\n          172.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 110.78081035323044,\n        \"min\": 0.0,\n        \"max\": 603.0,\n        \"num_unique_values\": 217,\n        \"samples\": [\n          384.0,\n          333.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"lv hypertrophy\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.926276492797612,\n        \"min\": 60.0,\n        \"max\": 202.0,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          185.0,\n          134.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0912262483465265,\n        \"min\": -2.6,\n        \"max\": 6.2,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          2.4,\n          -1.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"downsloping\",\n          \"flat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9356530125599879,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"fixed defect\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Drop irrelevant column"
      ],
      "metadata": {
        "id": "Npnv7A32jqgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['id', 'dataset'], inplace=True)"
      ],
      "metadata": {
        "id": "6EqeD0fej0Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Handle missing values\n",
        "# Numerical"
      ],
      "metadata": {
        "id": "3LMBd_OakXI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "df[num_cols] = num_imputer.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "V96S3xU8kgOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical"
      ],
      "metadata": {
        "id": "_E7_dx7okkfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])"
      ],
      "metadata": {
        "id": "W0jw6mUHknuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Encode categorical columns"
      ],
      "metadata": {
        "id": "l3p4DtaFkrwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n"
      ],
      "metadata": {
        "id": "v_4VGzw8kvFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Convert target to binary: 0 (no disease), 1 (disease)"
      ],
      "metadata": {
        "id": "ZWA2NbOxk0Xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['num'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n"
      ],
      "metadata": {
        "id": "33lKXYn-k4IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Split data"
      ],
      "metadata": {
        "id": "4QXVCjbEk8XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('num', axis=1)\n",
        "y = df['num']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "0zUYpmHIlATp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Scale features\n",
        "We use StandardScaler from sklearn.preprocessing to standardize the features before training machine learning models.\n",
        "Because many ML models perform better and converge faster when input features are on a similar scale."
      ],
      "metadata": {
        "id": "jvLpqJXXlD5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "2HHOrFaFlGo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*9..*Logistic Regression* is a supervised machine learning algorithm used primarily for binary classification tasks â€” where the goal is to predict one of two possible outcomes, like:\n",
        "\n",
        "Will a person get heart disease? â†’ Yes (1) or No (0)\n",
        "\n",
        "Is an email spam? â†’ Spam (1) or Not Spam (0)"
      ],
      "metadata": {
        "id": "cM8cGgqMv2Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ” Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cAJf3qaxCRo",
        "outputId": "7871bd4c-9c84-4ded-d79f-e923275264ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Logistic Regression\n",
            "Accuracy: 0.7717391304347826\n",
            "Confusion Matrix:\n",
            " [[60 15]\n",
            " [27 82]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.80      0.74        75\n",
            "           1       0.85      0.75      0.80       109\n",
            "\n",
            "    accuracy                           0.77       184\n",
            "   macro avg       0.77      0.78      0.77       184\n",
            "weighted avg       0.78      0.77      0.77       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Logistic Regression Prediction in Python"
      ],
      "metadata": {
        "id": "_N-rPiyArAJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Lmyxj6m-pMkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Define inputs\n",
        "x = 2.5        # Input feature\n",
        "w = 1.2        # Weight\n",
        "b = -2         # Bias\n",
        "\n",
        "# Step 2: Calculate linear combination (z = w*x + b)\n",
        "z = w * x + b\n",
        "\n",
        "# Step 3: Apply sigmoid function\n",
        "y_pred = 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Step 4: Output prediction\n",
        "print(\"z (linear output):\", z)\n",
        "print(\"Predicted probability (sigmoid output):\", y_pred)\n",
        "\n",
        "# Step 5: Classify using threshold\n",
        "predicted_class = 1 if y_pred >= 0.5 else 0\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrq-WnMYIHdR",
        "outputId": "c8796721-bcda-443f-c7e6-949cba659b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z (linear output): 1.0\n",
            "Predicted probability (sigmoid output): 0.7310585786300049\n",
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: Decision Tree\n",
        "\n",
        "A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. It works by splitting the dataset into branches based on feature values, forming a tree-like structure of decisions.\n",
        "\n"
      ],
      "metadata": {
        "id": "uLs9z6OrxMsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O1_2COpvrDFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸŒ³ Decision Tree\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC1biOvdxeCJ",
        "outputId": "3d41af65-748e-48e8-fbfc-352c6f14253d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ³ Decision Tree\n",
            "Accuracy: 0.8152173913043478\n",
            "Confusion Matrix:\n",
            " [[60 15]\n",
            " [19 90]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.80      0.78        75\n",
            "           1       0.86      0.83      0.84       109\n",
            "\n",
            "    accuracy                           0.82       184\n",
            "   macro avg       0.81      0.81      0.81       184\n",
            "weighted avg       0.82      0.82      0.82       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Logistic Regression Prediction in Python"
      ],
      "metadata": {
        "id": "h1WkR1nYrg1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_decision_tree(age, cholesterol):\n",
        "    if age > 50:\n",
        "        return 0  # No disease\n",
        "    else:\n",
        "        if cholesterol > 200:\n",
        "            return 1  # Disease\n",
        "        else:\n",
        "            return 0  # No disease\n",
        "\n",
        "# Test examples\n",
        "print(\"Prediction 1:\", manual_decision_tree(45, 210))  # Expected: 1\n",
        "print(\"Prediction 2:\", manual_decision_tree(60, 160))  # Expected: 0\n",
        "print(\"Prediction 3:\", manual_decision_tree(50, 180))  # Expected: 0\n",
        "print(\"Prediction 4:\", manual_decision_tree(50, 240))  # Expected: 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR6db7jErhxg",
        "outputId": "3414f96f-a3b6-48fc-8462-bc0c501b8b6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 1: 1\n",
            "Prediction 2: 0\n",
            "Prediction 3: 0\n",
            "Prediction 4: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: Random Forest\n",
        "\n",
        "A Random Forest is a powerful ensemble learning method used for classification and regression tasks. Its main function is to improve prediction accuracy and control overfitting by combining the results of multiple decision trees."
      ],
      "metadata": {
        "id": "WD0Sub9ixm5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸŒ² Random Forest\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zbjsh5Wx1Hk",
        "outputId": "61c78ef9-c451-4d31-b73d-9f0776cf8d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ² Random Forest\n",
            "Accuracy: 0.842391304347826\n",
            "Confusion Matrix:\n",
            " [[66  9]\n",
            " [20 89]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.88      0.82        75\n",
            "           1       0.91      0.82      0.86       109\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.84      0.84       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define simple trees manually\n",
        "def tree1(age, cholesterol):\n",
        "    if age > 50:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def tree2(age, cholesterol):\n",
        "    if cholesterol > 240:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def tree3(age, cholesterol):\n",
        "    if age <= 45:\n",
        "        return 1\n",
        "    else:\n",
        "        if cholesterol > 200:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "# Combine trees into a random forest\n",
        "def random_forest_predict(age, cholesterol):\n",
        "    predictions = []\n",
        "    predictions.append(tree1(age, cholesterol))\n",
        "    predictions.append(tree2(age, cholesterol))\n",
        "    predictions.append(tree3(age, cholesterol))\n",
        "\n",
        "    # Majority voting\n",
        "    prediction = max(set(predictions), key=predictions.count)\n",
        "    return prediction\n",
        "\n",
        "# Test predictions\n",
        "print(\"Prediction 1:\", random_forest_predict(60, 250))  # Expected 1 or 0 based on votes\n",
        "print(\"Prediction 2:\", random_forest_predict(40, 180))  # Expected 1\n",
        "print(\"Prediction 3:\", random_forest_predict(52, 190))  # Expected 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qxo8Jt6t4V_",
        "outputId": "284a54ce-5298-4e99-a629-21ee7f43cba1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 1: 1\n",
            "Prediction 2: 1\n",
            "Prediction 3: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4: SVM\n",
        "\n",
        "Support Vector Machine (SVM) is a supervised learning algorithm used primarily for classification (and sometimes regression). Its main function is to find the best boundary (called a hyperplane) that separates classes of data with the widest possible margin.\n",
        "\n"
      ],
      "metadata": {
        "id": "ftvhJVcYyA1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(probability=True)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ§­ Support Vector Machine\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_81Y1P3XyNlJ",
        "outputId": "8a5c3149-c7cf-455e-ee87-d69c76137cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§­ Support Vector Machine\n",
            "Accuracy: 0.8478260869565217\n",
            "Confusion Matrix:\n",
            " [[65 10]\n",
            " [18 91]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82        75\n",
            "           1       0.90      0.83      0.87       109\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.85      0.85       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Define the input point (feature vector)\n",
        "x = np.array([2, 3])  # Example point with 2 features\n",
        "\n",
        "# Step 2: Define the SVM model parameters\n",
        "# These would normally be learned during training\n",
        "w = np.array([1, -1])  # Weight vector (slope of decision boundary)\n",
        "b = -0.5               # Bias (intercept)\n",
        "\n",
        "# Step 3: Compute the decision function (w.x + b)\n",
        "z = np.dot(w, x) + b\n",
        "\n",
        "# Step 4: Make prediction based on the sign of the decision function\n",
        "if z >= 0:\n",
        "    prediction = 1  # Class 1\n",
        "else:\n",
        "    prediction = 0  # Class 0\n",
        "\n",
        "# Step 5: Output results\n",
        "print(\"Input features:\", x)\n",
        "print(\"Decision function output (z):\", z)\n",
        "print(\"Predicted class:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFRb8pOCwFF6",
        "outputId": "26ac0267-ebfa-4b59-b6ab-0420cd86f105"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input features: [2 3]\n",
            "Decision function output (z): -1.5\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Model 5: KNN\n",
        "\n",
        " The K-Nearest Neighbors (KNN) algorithm is a supervised machine learning model used for classification and regression. Its function is to predict the label of a new data point based on the majority class (or average value) of its nearest neighbors in the training set."
      ],
      "metadata": {
        "id": "4hLojCYTyaqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ‘¥ K-Nearest Neighbors\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M60bc5z4yntc",
        "outputId": "1e574a33-a545-4ac8-ad83-c6aab6f34a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ‘¥ K-Nearest Neighbors\n",
            "Accuracy: 0.7934782608695652\n",
            "Confusion Matrix:\n",
            " [[63 12]\n",
            " [26 83]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.84      0.77        75\n",
            "           1       0.87      0.76      0.81       109\n",
            "\n",
            "    accuracy                           0.79       184\n",
            "   macro avg       0.79      0.80      0.79       184\n",
            "weighted avg       0.81      0.79      0.80       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Define training data (features and labels)\n",
        "X_train = np.array([\n",
        "    [1, 2],   # Class 0\n",
        "    [2, 3],   # Class 0\n",
        "    [3, 1],   # Class 1\n",
        "    [6, 5],   # Class 1\n",
        "    [7, 7],   # Class 1\n",
        "    [8, 6]    # Class 1\n",
        "])\n",
        "y_train = np.array([0, 0, 1, 1, 1, 1])\n",
        "\n",
        "# Step 2: Define a new data point to classify\n",
        "x_test = np.array([3, 3])\n",
        "\n",
        "# Step 3: Set number of neighbors\n",
        "k = 3\n",
        "\n",
        "# Step 4: Compute Euclidean distances from x_test to all points in X_train\n",
        "distances = []\n",
        "for i in range(len(X_train)):\n",
        "    distance = np.linalg.norm(X_train[i] - x_test)\n",
        "    distances.append((distance, y_train[i]))\n",
        "\n",
        "# Step 5: Sort distances and select the top k nearest neighbors\n",
        "sorted_distances = sorted(distances, key=lambda x: x[0])\n",
        "top_k = sorted_distances[:k]\n",
        "\n",
        "# Step 6: Extract the labels of the top k neighbors\n",
        "k_labels = [label for _, label in top_k]\n",
        "\n",
        "# Step 7: Predict the majority class\n",
        "prediction = Counter(k_labels).most_common(1)[0][0]\n",
        "\n",
        "# Output\n",
        "print(f\"Test point: {x_test}\")\n",
        "print(f\"Top {k} neighbors' labels: {k_labels}\")\n",
        "print(f\"Predicted class: {prediction}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnN8c31mxTzn",
        "outputId": "cf56bd96-4d9e-4bc7-92d6-bff50fb0ae92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test point: [3 3]\n",
            "Top 3 neighbors' labels: [np.int64(0), np.int64(1), np.int64(0)]\n",
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 6: Naive Bayes function\n",
        "The Naive Bayes classifier is a probabilistic machine learning model based on Bayes' Theorem. Its function is to predict the probability that a data point belongs to a particular class based on prior knowledge from the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "F1RXjLyCyvnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ“Š Naive Bayes\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh6uQUnrzCSl",
        "outputId": "3c5b452d-0713-479c-9e19-a51de953c571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Naive Bayes\n",
            "Accuracy: 0.7880434782608695\n",
            "Confusion Matrix:\n",
            " [[62 13]\n",
            " [26 83]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.83      0.76        75\n",
            "           1       0.86      0.76      0.81       109\n",
            "\n",
            "    accuracy                           0.79       184\n",
            "   macro avg       0.78      0.79      0.79       184\n",
            "weighted avg       0.80      0.79      0.79       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sample dataset\n",
        "X_train = np.array([\n",
        "    [1, 1],\n",
        "    [2, 1],\n",
        "    [1, 0],\n",
        "    [2, 0],\n",
        "    [3, 1],\n",
        "    [3, 0]\n",
        "])\n",
        "\n",
        "y_train = np.array([0, 0, 1, 1, 0, 1])  # 0: No Disease, 1: Disease\n",
        "\n",
        "# Step 1: Separate data by class\n",
        "data_by_class = defaultdict(list)\n",
        "for x, label in zip(X_train, y_train):\n",
        "    data_by_class[label].append(x)\n",
        "\n",
        "# Step 2: Compute mean and variance per class per feature\n",
        "model = {}\n",
        "for label, features in data_by_class.items():\n",
        "    features = np.array(features)\n",
        "    mean = features.mean(axis=0)\n",
        "    var = features.var(axis=0)\n",
        "    model[label] = {'mean': mean, 'var': var, 'prior': len(features) / len(X_train)}\n",
        "\n",
        "# Step 3: Define Gaussian probability density function\n",
        "def gaussian(x, mean, var):\n",
        "    eps = 1e-6  # for numerical stability\n",
        "    coef = 1.0 / np.sqrt(2 * np.pi * var + eps)\n",
        "    exp = np.exp(-((x - mean) ** 2) / (2 * var + eps))\n",
        "    return coef * exp\n",
        "\n",
        "# Step 4: Predict function\n",
        "def predict(x):\n",
        "    probs = {}\n",
        "    for label in model:\n",
        "        prior = np.log(model[label]['prior'])\n",
        "        class_conditional = np.sum(np.log(gaussian(x, model[label]['mean'], model[label]['var'])))\n",
        "        probs[label] = prior + class_conditional\n",
        "    return max(probs, key=probs.get)\n",
        "\n",
        "# Step 5: Test prediction\n",
        "x_test = np.array([2, 1])\n",
        "prediction = predict(x_test)\n",
        "print(\"Predicted class:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4fvgt5EzZjk",
        "outputId": "4aeaff39-cca4-4eb1-97ca-3f737a08662c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1344600165.py:41: RuntimeWarning: divide by zero encountered in log\n",
            "  class_conditional = np.sum(np.log(gaussian(x, model[label]['mean'], model[label]['var'])))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 7: AdaBoost\n",
        "AdaBoost (short for Adaptive Boosting) is an ensemble learning algorithm that combines multiple weak learners (typically decision stumps) into a strong classifier. Its main function is to boost the performance of weak models by focusing on the errors made in previous iterations."
      ],
      "metadata": {
        "id": "FRJ1VpNjzTZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"âš¡ AdaBoost\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuCgQVH5zoMz",
        "outputId": "0d6d36ae-abdc-44cd-e3d5-9ba4242d73f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ AdaBoost\n",
            "Accuracy: 0.8206521739130435\n",
            "Confusion Matrix:\n",
            " [[64 11]\n",
            " [22 87]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.80        75\n",
            "           1       0.89      0.80      0.84       109\n",
            "\n",
            "    accuracy                           0.82       184\n",
            "   macro avg       0.82      0.83      0.82       184\n",
            "weighted avg       0.83      0.82      0.82       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample dataset (6 points, 2 features, binary labels)\n",
        "X = np.array([[1, 2],\n",
        "              [2, 1],\n",
        "              [2, 3],\n",
        "              [3, 2],\n",
        "              [3, 3],\n",
        "              [4, 5]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1])  # Binary labels\n",
        "\n",
        "# Convert labels to -1 and 1\n",
        "y = np.where(y == 0, -1, 1)\n",
        "\n",
        "# Weak learner: Decision Stump\n",
        "class DecisionStump:\n",
        "    def __init__(self):\n",
        "        self.feature_index = None\n",
        "        self.threshold = None\n",
        "        self.polarity = 1\n",
        "        self.alpha = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        n = X.shape[0]\n",
        "        predictions = np.ones(n)\n",
        "        feature_values = X[:, self.feature_index]\n",
        "        if self.polarity == 1:\n",
        "            predictions[feature_values < self.threshold] = -1\n",
        "        else:\n",
        "            predictions[feature_values > self.threshold] = -1\n",
        "        return predictions\n",
        "\n",
        "# Initialize\n",
        "n_samples, n_features = X.shape\n",
        "n_estimators = 3  # Number of weak learners\n",
        "w = np.full(n_samples, (1 / n_samples))  # Equal weight initially\n",
        "\n",
        "models = []\n",
        "\n",
        "for _ in range(n_estimators):\n",
        "    stump = DecisionStump()\n",
        "    min_error = float('inf')\n",
        "\n",
        "    # Search best stump\n",
        "    for feature_i in range(n_features):\n",
        "        values = np.unique(X[:, feature_i])\n",
        "        for threshold in values:\n",
        "            for polarity in [1, -1]:\n",
        "                pred = np.ones(n_samples)\n",
        "                if polarity == 1:\n",
        "                    pred[X[:, feature_i] < threshold] = -1\n",
        "                else:\n",
        "                    pred[X[:, feature_i] > threshold] = -1\n",
        "                error = np.sum(w[pred != y])\n",
        "                if error < min_error:\n",
        "                    min_error = error\n",
        "                    stump.polarity = polarity\n",
        "                    stump.threshold = threshold\n",
        "                    stump.feature_index = feature_i\n",
        "\n",
        "    # Calculate alpha (lear\n"
      ],
      "metadata": {
        "id": "YPqJR1ht0xax"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rrvhGKWZ0KcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Model 8: Gradient Boosting\n",
        "\n",
        " Gradient Boosting is an ensemble learning technique used for both classification and regression tasks. Its main function is to build a strong predictive model by combining several weak learners, typically decision trees, trained sequentially â€” each one trying to correct the errors made by the previous ones."
      ],
      "metadata": {
        "id": "v2psN3lXzzBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸš€ Gradient Boosting\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME-Ixxpiz9kK",
        "outputId": "11191510-27de-42f7-a89f-bcb3cd6d2bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Gradient Boosting\n",
            "Accuracy: 0.8097826086956522\n",
            "Confusion Matrix:\n",
            " [[63 12]\n",
            " [23 86]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.84      0.78        75\n",
            "           1       0.88      0.79      0.83       109\n",
            "\n",
            "    accuracy                           0.81       184\n",
            "   macro avg       0.81      0.81      0.81       184\n",
            "weighted avg       0.82      0.81      0.81       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample dataset (features and binary labels)\n",
        "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1])  # binary labels\n",
        "\n",
        "# Convert to float and normalize labels to match regression form\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Decision stump for regression\n",
        "class DecisionStumpRegressor:\n",
        "    def __init__(self):\n",
        "        self.feature_index = None\n",
        "        self.threshold = None\n",
        "        self.left_value = None\n",
        "        self.right_value = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "        min_error = float('inf')\n",
        "\n",
        "        for feature_i in range(n):\n",
        "            thresholds = np.unique(X[:, feature_i])\n",
        "            for threshold in thresholds:\n",
        "                left_idx = X[:, feature_i] <= threshold\n",
        "                right_idx = X[:, feature_i] > threshold\n",
        "                if len(y[left_idx]) == 0 or len(y[right_idx]) == 0:\n",
        "                    continue\n",
        "\n",
        "                left_val = np.mean(y[left_idx])\n",
        "                right_val = np.mean(y[right_idx])\n",
        "                predictions = np.where(X[:, feature_i] <= threshold, left_val, right_val)\n",
        "                error = np.mean((y - predictions) ** 2)\n",
        "\n",
        "                if error < min_error:\n",
        "                    min_error = error\n",
        "                    self.feature_index = feature_i\n",
        "                    self.threshold = threshold\n",
        "                    self.left_value = left_val\n",
        "                    self.righ\n"
      ],
      "metadata": {
        "id": "iQuisjhf08hX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 9: XGBoost\n",
        "XGBoost is an advanced implementation of the Gradient Boosting algorithm. Its function is to build a series of decision trees where each tree tries to correct the errors of the previous one, just like traditional gradient boosting â€” but much faster and more accurate thanks to optimized techniques."
      ],
      "metadata": {
        "id": "dBR68fQH0O9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ”· XGBoost\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC3vmeb90X6Z",
        "outputId": "1ee99779-a99a-46da-f94a-eaee955c81bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”· XGBoost\n",
            "Accuracy: 0.8478260869565217\n",
            "Confusion Matrix:\n",
            " [[65 10]\n",
            " [18 91]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82        75\n",
            "           1       0.90      0.83      0.87       109\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.85      0.85       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample binary classification dataset\n",
        "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
        "y = np.array([0, 0, 1, 1, 1, 1])\n",
        "\n",
        "# Sigmoid function for logistic loss\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Simple decision stump regressor (1-level tree)\n",
        "class SimpleXGBoostTree:\n",
        "    def __init__(self):\n",
        "        self.feature_index = None\n",
        "        self.threshold = None\n",
        "        self.left_output = None\n",
        "        self.right_output = None\n",
        "\n",
        "    def calc_leaf_value(self, grad, hess):\n",
        "        return -np.sum(grad) / (np.sum(hess) + 1e-6)  # Add small value to avoid div by 0\n",
        "\n",
        "    def fit(self, X, grad, hess):\n",
        "        m, n = X.shape\n",
        "        best_gain =_\n"
      ],
      "metadata": {
        "id": "OGof-m7-1LQb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Model 10: LightGBM\n",
        "\n",
        " LightGBM is a high-performance gradient boosting framework developed by Microsoft. Its main function is to build fast, accurate models using decision trees â€” especially effective on large datasets with many features."
      ],
      "metadata": {
        "id": "8Ec0U4Go0k3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "print(\"ðŸ’¡ LightGBM\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh97JfGf0u5w",
        "outputId": "4606446f-4381-48a3-f38a-1f9ec6d1bffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 400, number of negative: 336\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 736, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.543478 -> initscore=0.174353\n",
            "[LightGBM] [Info] Start training from score 0.174353\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "ðŸ’¡ LightGBM\n",
            "Accuracy: 0.8641304347826086\n",
            "Confusion Matrix:\n",
            " [[68  7]\n",
            " [18 91]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.91      0.84        75\n",
            "           1       0.93      0.83      0.88       109\n",
            "\n",
            "    accuracy                           0.86       184\n",
            "   macro avg       0.86      0.87      0.86       184\n",
            "weighted avg       0.87      0.86      0.87       184\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Binary classification dataset\n",
        "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
        "y = np.array([0, 0, 1, 1, 1, 1])\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class SimpleLightGBMTree:\n",
        "    def __init__(self):\n",
        "        self.feature_index = None\n",
        "        self.threshold = None\n",
        "        self.left_output = None\n",
        "        self.right_output = None\n",
        "\n",
        "    def _leaf_output(self, grad, hess):\n",
        "        return -np.sum(grad) / (np.sum(hess) + 1e-6)\n",
        "\n",
        "    def fit(self, X, grad, hess):\n",
        "        best_gain = -np.inf\n",
        "        m, n = X.shape\n",
        "\n",
        "        for i in range(n):\n",
        "            for t in np.unique(X[:, i]):\n",
        "                left = X[:, i] <= t\n",
        "                right = X[:, i] > t\n",
        "\n",
        "                if np.sum(left) == 0 or np.sum(right) == 0:\n",
        "                    continue\n",
        "\n",
        "                G_left, H_left = np.sum(grad[left]), np.sum(hess[left])\n",
        "                G_right, H_right = np.sum(grad[right]), np.sum(hess[right])\n",
        "\n",
        "                # Gain function (like LightGBM)\n",
        "                gain = (G_left ** 2) / (H_left + 1e-6) + (G_right ** 2) / (H_right + 1e-6)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    self.feature_index = i\n",
        "                    self.threshold = t\n",
        "                    self.left_output = self._leaf_output(grad[left], hess[left])\n",
        "                    self.right_output = self._leaf_output(grad[right], hess[right])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(X[:, self.feature_index] <= self.threshold,\n",
        "                        self.left_output, self.right_output)\n",
        "\n",
        "class SimpleLightGBM:\n",
        "    def __init__(self, n_estimators=3, learning_rate=0.5):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.trees = []\n",
        "        self.base_score = 0.5\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        pred = np.full(y.shape, self.base_score)\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            prob = sigmoid(pred)\n",
        "            grad = prob - y\n",
        "            hess = prob * (1 - prob)\n",
        "\n",
        "            tree = SimpleLightGBMTree()\n",
        "            tree.fit(X, grad, hess)\n",
        "\n",
        "            update = tree.predict(X)\n",
        "            pred += self.learning_rate * update\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred = np.full((X.shape[0],), self.base_score)\n",
        "        for tree in self.trees:\n",
        "            pred += self.learning_rate * tree.predict(X)\n",
        "        return np.where(sigmoid(pred) >= 0.5, 1, 0)\n",
        "\n",
        "# Train model\n",
        "model = SimpleLightGBM(n_estimators=3, learning_rate=0.5)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Test\n",
        "X_test = np.array([[2], [3], [5]])\n",
        "pred = model.predict(X_test)\n",
        "print(\"Predictions:\", pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aPQXBsR1Z2b",
        "outputId": "ea0b5209-9128-4bb3-8b76-e28303375b4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N3WsWM7-lMAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Define models"
      ],
      "metadata": {
        "id": "kyEOIfYzlMDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, preds))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLdr4mqel40-",
        "outputId": "b21749b7-1ff5-4edd-db01-28a3386b4727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Logistic Regression ---\n",
            "Accuracy: 0.7717\n",
            "Confusion Matrix:\n",
            "[[60 15]\n",
            " [27 82]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.80      0.74        75\n",
            "           1       0.85      0.75      0.80       109\n",
            "\n",
            "    accuracy                           0.77       184\n",
            "   macro avg       0.77      0.78      0.77       184\n",
            "weighted avg       0.78      0.77      0.77       184\n",
            "\n",
            "\n",
            "\n",
            "--- Decision Tree ---\n",
            "Accuracy: 0.8152\n",
            "Confusion Matrix:\n",
            "[[63 12]\n",
            " [22 87]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.84      0.79        75\n",
            "           1       0.88      0.80      0.84       109\n",
            "\n",
            "    accuracy                           0.82       184\n",
            "   macro avg       0.81      0.82      0.81       184\n",
            "weighted avg       0.82      0.82      0.82       184\n",
            "\n",
            "\n",
            "\n",
            "--- Random Forest ---\n",
            "Accuracy: 0.8696\n",
            "Confusion Matrix:\n",
            "[[68  7]\n",
            " [17 92]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85        75\n",
            "           1       0.93      0.84      0.88       109\n",
            "\n",
            "    accuracy                           0.87       184\n",
            "   macro avg       0.86      0.88      0.87       184\n",
            "weighted avg       0.88      0.87      0.87       184\n",
            "\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "Accuracy: 0.8478\n",
            "Confusion Matrix:\n",
            "[[65 10]\n",
            " [18 91]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82        75\n",
            "           1       0.90      0.83      0.87       109\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.85      0.85       184\n",
            "\n",
            "\n",
            "\n",
            "--- KNN ---\n",
            "Accuracy: 0.7935\n",
            "Confusion Matrix:\n",
            "[[63 12]\n",
            " [26 83]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.84      0.77        75\n",
            "           1       0.87      0.76      0.81       109\n",
            "\n",
            "    accuracy                           0.79       184\n",
            "   macro avg       0.79      0.80      0.79       184\n",
            "weighted avg       0.81      0.79      0.80       184\n",
            "\n",
            "\n",
            "\n",
            "--- Naive Bayes ---\n",
            "Accuracy: 0.7880\n",
            "Confusion Matrix:\n",
            "[[62 13]\n",
            " [26 83]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.83      0.76        75\n",
            "           1       0.86      0.76      0.81       109\n",
            "\n",
            "    accuracy                           0.79       184\n",
            "   macro avg       0.78      0.79      0.79       184\n",
            "weighted avg       0.80      0.79      0.79       184\n",
            "\n",
            "\n",
            "\n",
            "--- Gradient Boosting ---\n",
            "Accuracy: 0.8098\n",
            "Confusion Matrix:\n",
            "[[63 12]\n",
            " [23 86]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.84      0.78        75\n",
            "           1       0.88      0.79      0.83       109\n",
            "\n",
            "    accuracy                           0.81       184\n",
            "   macro avg       0.81      0.81      0.81       184\n",
            "weighted avg       0.82      0.81      0.81       184\n",
            "\n",
            "\n",
            "\n",
            "--- AdaBoost ---\n",
            "Accuracy: 0.8207\n",
            "Confusion Matrix:\n",
            "[[64 11]\n",
            " [22 87]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.80        75\n",
            "           1       0.89      0.80      0.84       109\n",
            "\n",
            "    accuracy                           0.82       184\n",
            "   macro avg       0.82      0.83      0.82       184\n",
            "weighted avg       0.83      0.82      0.82       184\n",
            "\n",
            "\n",
            "\n",
            "--- XGBoost ---\n",
            "Accuracy: 0.8478\n",
            "Confusion Matrix:\n",
            "[[65 10]\n",
            " [18 91]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82        75\n",
            "           1       0.90      0.83      0.87       109\n",
            "\n",
            "    accuracy                           0.85       184\n",
            "   macro avg       0.84      0.85      0.84       184\n",
            "weighted avg       0.85      0.85      0.85       184\n",
            "\n",
            "\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 400, number of negative: 336\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 736, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.543478 -> initscore=0.174353\n",
            "[LightGBM] [Info] Start training from score 0.174353\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "--- LightGBM ---\n",
            "Accuracy: 0.8641\n",
            "Confusion Matrix:\n",
            "[[68  7]\n",
            " [18 91]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.91      0.84        75\n",
            "           1       0.93      0.83      0.88       109\n",
            "\n",
            "    accuracy                           0.86       184\n",
            "   macro avg       0.86      0.87      0.86       184\n",
            "weighted avg       0.87      0.86      0.87       184\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot accuracy comparison"
      ],
      "metadata": {
        "id": "dmYguqhGnFUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dictionary to store accuracy scores\n",
        "accuracy_scores = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    accuracy_scores[name] = acc\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n",
        "# Plot accuracy comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(accuracy_scores.keys(), accuracy_scores.values(), color='skyblue')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1H6CnTaVm78X",
        "outputId": "12ca7db9-f711-4ab4-e61b-b0d1e0b895a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: 0.7717\n",
            "Decision Tree: 0.8098\n",
            "Random Forest: 0.8315\n",
            "SVM: 0.8478\n",
            "KNN: 0.7935\n",
            "Naive Bayes: 0.7880\n",
            "Gradient Boosting: 0.8098\n",
            "AdaBoost: 0.8207\n",
            "XGBoost: 0.8478\n",
            "[LightGBM] [Info] Number of positive: 400, number of negative: 336\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 736, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.543478 -> initscore=0.174353\n",
            "[LightGBM] [Info] Start training from score 0.174353\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM: 0.8641\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}